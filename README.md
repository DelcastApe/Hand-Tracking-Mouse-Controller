# ğŸ–ï¸ HandMouse AI â€” AI-Powered Hand Tracking Mouse Controller

HandMouse AI is a computer-vision project that lets you control your computer **entirely with hand gestures**, using a standard webcam.  
Inspired by AR/VR (XR) interaction systems like Meta Quest, this project uses:

- **MediaPipe Hands** â†’ precise detection of 21 hand landmarks  
- **OpenCV** â†’ real-time video processing  
- **PyAutoGUI** â†’ system-level mouse control  
- **Automatic Vertical Calibration** â†’ adapts instantly to any webcam and user  

No setup, no manual calibration â€” just run it and move your hand.

---

## ğŸš€ Features

### âœ” Full Mouse Control with Hand Gestures
- **Move cursor** â†’ raise your index finger  
- **Left click** â†’ pinch (thumb + index finger)  
- **Right click** â†’ pinch (thumb + middle finger)  
- **Real-time tracking** with smooth or fast-response modes

### âœ” Automatic Vertical Calibration (PRO feature)
The system continually learns:

- your **highest** index-finger position  
- your **lowest** index-finger position  

and maps that range to **100% of the screen height**, enabling:

- reaching the taskbar and bottom icons  
- consistent behavior on any camera  
- adaptation to users of different heights and hand positions  
- instant adjustment when the camera moves or lighting changes  

### âœ” Extremely Smooth or Ultra-Responsive
Choose your preferred control style:

- `alpha = 1.0` â†’ zero lag, XR-style, ultra-responsive  
- `alpha = 0.9` â†’ smooth but still fast  

### âœ” Works with Any Webcam
No depth sensors or special hardware required.

---

## ğŸ“ Project Structure

```

hand-mouse-controller/
â”‚â”€â”€ src/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ hand_tracker.py
â”‚   â”œâ”€â”€ gesture_detector.py
â”‚   â”œâ”€â”€ mouse_controller.py
â”‚   â”œâ”€â”€ config.py
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ smoothing.py
â”‚       â””â”€â”€ **init**.py
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore

````

---

## ğŸ›  Installation

### 1ï¸âƒ£ Create virtual environment

```bash
python -m venv .venv
````

### 2ï¸âƒ£ Activate the environment

**Windows**

```bash
.\.venv\Scripts\activate
```

**Mac/Linux**

```bash
source .venv/bin/activate
```

### 3ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

---

## â–¶ Running the App

```bash
python src/main.py
```

Then:

* Raise only your **index finger** â†’ move cursor
* Thumb + index â†’ **Left Click**
* Thumb + middle finger â†’ **Right Click**
* Move hand up/down â†’ auto-calibration adapts to your range
* Press **ESC** or **Q** to exit

A message at the bottom of the window reminds you that calibration is automatic.

---

## ğŸ’¡ How Automatic Vertical Calibration Works

The system continuously observes:

* the **minimum Y** position of your index finger
* the **maximum Y** position

As soon as it sees new extremes, it expands the range and maps that dynamic interval to:

```
index_finger_highest  â†’  top of the screen
index_finger_lowest   â†’  bottom of the screen
```

This ensures:

* full access to screen corners
* effortless access to bottom icons/taskbar
* correct behavior even if the webcam doesnâ€™t see your whole arm
* seamless user adaptation

No manual steps required.

---

## ğŸ“¦ Technologies Used

* **Python 3.8+**
* **OpenCV**
* **MediaPipe Hands**
* **PyAutoGUI**
* **NumPy**

---

## ğŸ¯ Project Goal

To explore natural, hands-free interaction systems by combining computer vision and human-computer interaction (HCI), enabling new ways to control computers without physical input devices.

Great for:

* XR research
* HCI projects
* AI-driven interaction interfaces
* Real-time CV applications

---

## ğŸ‘¤ Author

Developed by **Jhonnatan Del Castillo**

Artificial Intelligence & Systems Engineering

Passionate about XR, computer vision, and next-gen human-computer interfaces.

---

## â­ Support the Project

If you like this:

* Star â­ the repo
* Share it
* Suggest new gestures (scroll, drag-and-drop, zoom, window controls, etc.)

Just Tell Me
---

